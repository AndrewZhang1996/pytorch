diff --git a/aten/src/THCUNN/THCHalfAutoNumerics.cuh b/aten/src/THCUNN/THCHalfAutoNumerics.cuh
<<<<<<< HEAD
index 2653fed0b..c4e9089e0 100644
--- a/aten/src/THCUNN/THCHalfAutoNumerics.cuh
+++ b/aten/src/THCUNN/THCHalfAutoNumerics.cuh
@@ -19,13 +19,17 @@ inline __host__ __device__ float fmaxType(float x, half y) {
 }
 #endif
 
+/* In ROCm we have a conversion from half to __fp16, and then there's a
+conversion operator from __fp16 to double (w/ the standard conversion
+double to float), so comment out these two lines to prevent ambiguous calls
+for fmaxType when half is passed in.
 inline __host__ __device__ float fmaxType(float x, float y) {
   return fmaxf(x, y);
 }
 
 inline __host__ __device__ double fmaxType(double x, double y) {
   return fmax(x, y);
-}
+}*/
 
 #ifdef CUDA_HALF_TENSOR
 
=======
index 2653fed0b..532242996 100644
--- a/aten/src/THCUNN/THCHalfAutoNumerics.cuh
+++ b/aten/src/THCUNN/THCHalfAutoNumerics.cuh
@@ -31,6 +31,8 @@ inline __host__ __device__ double fmaxType(double x, double y) {
 
 // arithmetic functions
 
+#if defined(__HIP_PLATFORM_HCC__)
+#else
 inline __host__ __device__ half operator+(half a, half b) {
   return THCNumerics<half>::add(a, b);
 }
@@ -159,6 +161,7 @@ inline __host__ __device__ half& operator/=(half &lhs, const half &rhs) {
   lhs = lhs / rhs;
   return lhs;
 }
+#endif
 
 inline __host__ __device__ half abs(half a) {
   return THCNumerics<half>::abs(a);
@@ -212,6 +215,8 @@ inline __host__ __device__ half operator*(half a, bool b) {
 
 // comparison functions
 
+#if defined(__HIP_PLATFORM_HCC__)
+#else
 inline __host__ __device__ bool operator<(half a, half b) {
   return THCNumerics<half>::lt(a, b);
 }
@@ -243,6 +248,7 @@ inline __host__ __device__ bool operator>=(half a, half b) {
 inline __host__ __device__ bool operator>=(half a, int b) {
   return THCNumerics<half>::ge(a, ScalarConvert<int ,half>::to(b));
 }
+#endif
 
 #endif
 #endif
>>>>>>> Seperated the individual patch files to make it easier to detect issues while building.
